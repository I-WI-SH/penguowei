{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def load_data(mode):\n",
    "\n",
    "    # 读取数据文件\n",
    "    datafile = './data/mnist.json.gz'\n",
    "    print('loading data from {}...',format(datafile))\n",
    "    data = json.load(gzip.open(datafile))\n",
    "\n",
    "    # 分别划分训练集，验证集，测试集 ===> data为一个长度为3的list\n",
    "    train_set, val_set, test_set = data\n",
    "\n",
    "    # 根据模型的应用方式，对数据集进行处理\n",
    "    if mode == 'train':\n",
    "        imgs = train_set[0]\n",
    "        labels = train_set[1]\n",
    "    elif mode == 'valid':\n",
    "        imgs = val_set[0]\n",
    "        labels = val_set[1]\n",
    "    elif mode == 'test':\n",
    "        imgs = test_set[0]\n",
    "        labels = test_set[1]\n",
    "    \n",
    "\n",
    "    # 验证图像数量和标签数量是否一致\n",
    "    assert len(imgs) == len(labels), \\\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\n",
    "                  len(imgs), len(labels))\n",
    "    \n",
    "    index_list = list(range(len(imgs)))\n",
    "\n",
    "    # 读入数据时用到的batchsize\n",
    "    BATCHSIZE = 100\n",
    "\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "\n",
    "    # 对数据进行预处理\n",
    "    def data_generator():\n",
    "        # 训练模式下，打乱训练数据\n",
    "        if mode == 'train':\n",
    "            random.shuffle(index_list)\n",
    "        imgs_list = []\n",
    "        labels_list = []\n",
    "        # 按照索引读取数据\n",
    "        for i in index_list:\n",
    "            # 读取图像和标签，转换其尺寸和类型\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "            label = np.reshape(labels[i], [1]).astype('int64')\n",
    "            imgs_list.append(img) \n",
    "            labels_list.append(label)\n",
    "            # 如果当前数据缓存达到了batch size，就返回一个批次数据\n",
    "            if len(imgs_list) == BATCHSIZE:\n",
    "                yield np.array(imgs_list), np.array(labels_list)\n",
    "                # 清空数据缓存列表\n",
    "                imgs_list = []\n",
    "                labels_list = []\n",
    "\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\n",
    "        if len(imgs_list) > 0:\n",
    "            yield np.array(imgs_list), np.array(labels_list)\n",
    "\n",
    "    return data_generator\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from {}... ./data/mnist.json.gz\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "# 读取数据文件\n",
    "datafile = './data/mnist.json.gz'\n",
    "print('loading data from {}...',format(datafile))\n",
    "data = json.load(gzip.open(datafile))\n",
    "\n",
    "# 分别划分训练集，验证集，测试集\n",
    "train_set, val_set, test_set = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_set[0]\n",
    "labels = train_set[1]\n",
    "\n",
    "label = train_set[1]\n",
    "index_list = list(range(len(imgs)))\n",
    "\n",
    "# 读入数据时用到的batchsize\n",
    "BATCHSIZE = 100\n",
    "\n",
    "# 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "\n",
    "random.shuffle(index_list)\n",
    "imgs_list = []\n",
    "labels_list = []    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9765625, -0.859375, -0.859375, -0.859375, -0.015625, 0.0625, 0.3671875, -0.796875, 0.296875, 0.9921875, 0.9296875, -0.0078125, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.765625, -0.71875, -0.265625, 0.203125, 0.328125, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.7578125, 0.34375, 0.9765625, 0.890625, 0.5234375, -0.5, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.6171875, 0.859375, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9609375, -0.2734375, -0.359375, -0.359375, -0.5625, -0.6953125, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.859375, 0.7109375, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.546875, 0.421875, 0.9296875, 0.8828125, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.375, 0.21875, -0.1640625, 0.9765625, 0.9765625, 0.6015625, -0.9140625, -1.0, -0.6640625, 0.203125, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.890625, -0.9921875, 0.203125, 0.9765625, -0.296875, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0859375, 0.9765625, 0.484375, -0.984375, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9140625, 0.484375, 0.9765625, -0.453125, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.7265625, 0.8828125, 0.7578125, 0.25, -0.15625, -0.9921875, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.3671875, 0.875, 0.9765625, 0.9765625, -0.0703125, -0.8046875, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.6484375, 0.453125, 0.9765625, 0.9765625, 0.171875, -0.7890625, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.875, -0.2734375, 0.96875, 0.9765625, 0.4609375, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.9453125, 0.9765625, 0.9453125, -0.5, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.640625, 0.015625, 0.4296875, 0.9765625, 0.9765625, 0.6171875, -0.984375, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.6953125, 0.15625, 0.7890625, 0.9765625, 0.9765625, 0.9765625, 0.953125, 0.421875, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.8125, -0.109375, 0.7265625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.5703125, -0.390625, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.8203125, -0.484375, 0.6640625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.546875, -0.3671875, -0.984375, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.859375, 0.3359375, 0.7109375, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.5234375, -0.375, -0.9296875, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.5703125, 0.34375, 0.765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.90625, 0.0390625, -0.9140625, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0625, 0.9765625, 0.9765625, 0.9765625, 0.65625, 0.0546875, 0.03125, -0.875, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "# 按照索引读取数据\n",
    "print(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -0.9765625, -0.859375 , -0.859375 ,\n",
       "         -0.859375 , -0.015625 ,  0.0625   ,  0.3671875, -0.796875 ,\n",
       "          0.296875 ,  0.9921875,  0.9296875, -0.0078125, -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -0.765625 , -0.71875  ,\n",
       "         -0.265625 ,  0.203125 ,  0.328125 ,  0.9765625,  0.9765625,\n",
       "          0.9765625,  0.9765625,  0.9765625,  0.7578125,  0.34375  ,\n",
       "          0.9765625,  0.890625 ,  0.5234375, -0.5      , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -0.6171875,  0.859375 ,  0.9765625,\n",
       "          0.9765625,  0.9765625,  0.9765625,  0.9765625,  0.9765625,\n",
       "          0.9765625,  0.9765625,  0.9609375, -0.2734375, -0.359375 ,\n",
       "         -0.359375 , -0.5625   , -0.6953125, -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -0.859375 ,  0.7109375,  0.9765625,\n",
       "          0.9765625,  0.9765625,  0.9765625,  0.9765625,  0.546875 ,\n",
       "          0.421875 ,  0.9296875,  0.8828125, -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -0.375    ,  0.21875  ,\n",
       "         -0.1640625,  0.9765625,  0.9765625,  0.6015625, -0.9140625,\n",
       "         -1.       , -0.6640625,  0.203125 , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -0.890625 ,\n",
       "         -0.9921875,  0.203125 ,  0.9765625, -0.296875 , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       ,  0.0859375,  0.9765625,  0.484375 , -0.984375 ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -0.9140625,  0.484375 ,  0.9765625, -0.453125 ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -0.7265625,  0.8828125,  0.7578125,\n",
       "          0.25     , -0.15625  , -0.9921875, -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -0.3671875,  0.875    ,\n",
       "          0.9765625,  0.9765625, -0.0703125, -0.8046875, -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -0.6484375,\n",
       "          0.453125 ,  0.9765625,  0.9765625,  0.171875 , -0.7890625,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -0.875    , -0.2734375,  0.96875  ,  0.9765625,  0.4609375,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       ,  0.9453125,  0.9765625,  0.9453125,\n",
       "         -0.5      , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -0.640625 ,\n",
       "          0.015625 ,  0.4296875,  0.9765625,  0.9765625,  0.6171875,\n",
       "         -0.984375 , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -0.6953125,  0.15625  ,  0.7890625,\n",
       "          0.9765625,  0.9765625,  0.9765625,  0.953125 ,  0.421875 ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -0.8125   , -0.109375 ,  0.7265625,  0.9765625,  0.9765625,\n",
       "          0.9765625,  0.9765625,  0.5703125, -0.390625 , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -0.8203125, -0.484375 ,\n",
       "          0.6640625,  0.9765625,  0.9765625,  0.9765625,  0.9765625,\n",
       "          0.546875 , -0.3671875, -0.984375 , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -0.859375 ,  0.3359375,  0.7109375,  0.9765625,\n",
       "          0.9765625,  0.9765625,  0.9765625,  0.5234375, -0.375    ,\n",
       "         -0.9296875, -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -0.5703125,\n",
       "          0.34375  ,  0.765625 ,  0.9765625,  0.9765625,  0.9765625,\n",
       "          0.9765625,  0.90625  ,  0.0390625, -0.9140625, -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       ,  0.0625   ,\n",
       "          0.9765625,  0.9765625,  0.9765625,  0.65625  ,  0.0546875,\n",
       "          0.03125  , -0.875    , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ],\n",
       "        [-1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "         -1.       , -1.       , -1.       ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.reshape(imgs[0], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.reshape(labels[0], [1]).astype('int64')\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_list.append(img) \n",
    "labels_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型结构\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\n",
    "# 多层卷积神经网络实现\n",
    "class MNIST(paddle.nn.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "         # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "         self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "         # 定义一层全连接层，输出维度是10\n",
    "         self.fc = Linear(in_features=980, out_features=10)\n",
    "         \n",
    "   # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "   # 卷积层激活函数使用Relu，全连接层激活函数使用softmax\n",
    "     def forward(self, inputs):\n",
    "         x = self.conv1(inputs)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool2(x)\n",
    "         x = paddle.reshape(x, [x.shape[0], -1])\n",
    "         x = self.fc(x)\n",
    "         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from {}... ./data/mnist.json.gz\n",
      "epoch: 0, batch: 0, loss is: [3.8579357]\n",
      "epoch: 0, batch: 200, loss is: [0.15703928]\n",
      "epoch: 0, batch: 400, loss is: [0.13316086]\n",
      "epoch: 1, batch: 0, loss is: [0.06132081]\n",
      "epoch: 1, batch: 200, loss is: [0.15065768]\n",
      "epoch: 1, batch: 400, loss is: [0.15679659]\n",
      "epoch: 2, batch: 0, loss is: [0.11170436]\n",
      "epoch: 2, batch: 200, loss is: [0.02675027]\n",
      "epoch: 2, batch: 400, loss is: [0.02749997]\n",
      "epoch: 3, batch: 0, loss is: [0.02256946]\n",
      "epoch: 3, batch: 200, loss is: [0.03588759]\n",
      "epoch: 3, batch: 400, loss is: [0.05811816]\n",
      "epoch: 4, batch: 0, loss is: [0.09757829]\n",
      "epoch: 4, batch: 200, loss is: [0.0065775]\n",
      "epoch: 4, batch: 400, loss is: [0.0069192]\n",
      "epoch: 5, batch: 0, loss is: [0.07676662]\n",
      "epoch: 5, batch: 200, loss is: [0.04595334]\n",
      "epoch: 5, batch: 400, loss is: [0.0477139]\n",
      "epoch: 6, batch: 0, loss is: [0.08200913]\n",
      "epoch: 6, batch: 200, loss is: [0.01611951]\n",
      "epoch: 6, batch: 400, loss is: [0.0798257]\n",
      "epoch: 7, batch: 0, loss is: [0.11030161]\n",
      "epoch: 7, batch: 200, loss is: [0.08088243]\n",
      "epoch: 7, batch: 400, loss is: [0.02579905]\n",
      "epoch: 8, batch: 0, loss is: [0.09953494]\n",
      "epoch: 8, batch: 200, loss is: [0.22356695]\n",
      "epoch: 8, batch: 400, loss is: [0.05539273]\n",
      "epoch: 9, batch: 0, loss is: [0.03990445]\n",
      "epoch: 9, batch: 200, loss is: [0.01152663]\n",
      "epoch: 9, batch: 400, loss is: [0.04028612]\n"
     ]
    }
   ],
   "source": [
    "#仅优化算法的设置有所差别\n",
    "def train(model):\n",
    "    model.train()\n",
    "    #调用加载数据的函数\n",
    "    train_loader = load_data('train')\n",
    "\n",
    "    #设置不同初始学习率\n",
    "    # opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.SGD(learning_rate=0.0001, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "\n",
    "    #四种优化算法的设置方案，可以逐一尝试效果\n",
    "    # opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Momentum(learning_rate=0.01, momentum=0.9, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adagrad(learning_rate=0.01, parameters=model.parameters())\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 10\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            #前向计算的过程\n",
    "            predicts = model(images)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            # 最小化loss,更新参数\n",
    "            opt.step()\n",
    "            # 清除梯度\n",
    "            opt.clear_grad()\n",
    "   \n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\n",
    "    \n",
    "#创建模型    \n",
    "model = MNIST()\n",
    "#启动训练过程\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次预测的数字是:  1\n"
     ]
    }
   ],
   "source": [
    "# 读取一张本地的样例图片，转变成模型输入的格式\n",
    "from PIL import Image\n",
    "def load_image(img_path):\n",
    "    # 从img_path中读取图像，并转为灰度图\n",
    "    im = Image.open(img_path).convert('L')\n",
    "    im = im.resize((28, 28), Image.LANCZOS)\n",
    "    im = np.array(im).reshape(1, 1, 28, 28).astype(np.float32)\n",
    "    # 图像归一化\n",
    "    im = 1.0 - im / 255.\n",
    "    return im\n",
    "\n",
    "# 定义预测过程\n",
    "model = MNIST()\n",
    "params_file_path = 'mnist.pdparams'\n",
    "img_path = 'data/example_0.png'\n",
    "# 加载模型参数\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "# 灌入数据\n",
    "model.eval()\n",
    "tensor_img = load_image(img_path)\n",
    "#模型反馈10个分类标签的对应概率\n",
    "results = model(paddle.to_tensor(tensor_img))\n",
    "#取概率最大的标签作为预测输出\n",
    "lab = np.argsort(results.numpy())\n",
    "print(\"本次预测的数字是: \", lab[0][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
